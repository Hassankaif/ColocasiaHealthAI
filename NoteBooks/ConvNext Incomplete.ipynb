{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10827936,"sourceType":"datasetVersion","datasetId":6723459}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ğŸ“Œ Enhanced ConvNeXt Training for Colocasia Disease Classification on Kaggle\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport os\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# âœ… Dataset path (Change to Kaggle path)\nBASE_PATH = \"/kaggle/input/colocasia-plant-datasets/Dataset\"  # Update this\n\n# âœ… Define class names\nCLASS_NAMES = [\n    'Disease_Leaf_Blight_Dorsal',\n    'Disease_Leaf_Blight_Ventral',\n    'Disease_Mosaic_Dorsal',\n    'Disease_Mosaic_Ventral',\n    'Healthy_Dorsal',\n    'Healthy_Ventral'\n]\n\n# âœ… Training Configuration\nCONFIG = {\n    'BATCH_SIZE': 16,  \n    'IMAGE_SIZE': (224, 224),  # Adjusted for ConvNeXt's input size\n    'NUM_CLASSES': len(CLASS_NAMES),\n    'EPOCHS': 20,\n    'K_FOLDS': 6,\n    'SEED': 42,\n    'LEARNING_RATE': 1e-4\n}\n\n# âœ… Setup output directories\nCHECKPOINT_DIR = \"./checkpoints\"\nRESULTS_DIR = \"./results\"\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\n# âœ… Load Dataset Efficiently\ndef load_dataset():\n    print(\"\\nğŸ“‚ Loading dataset with proper validation split...\")\n\n    full_dataset = image_dataset_from_directory(\n        BASE_PATH,\n        labels=\"inferred\",\n        label_mode=\"int\",\n        image_size=CONFIG['IMAGE_SIZE'],\n        batch_size=CONFIG['BATCH_SIZE'],\n        seed=CONFIG['SEED']\n    )\n\n    # âœ… Split dataset: 80% train, 20% validation\n    val_size = int(0.2 * tf.data.experimental.cardinality(full_dataset).numpy())\n    train_ds = full_dataset.skip(val_size)\n    val_ds = full_dataset.take(val_size)\n\n    # âœ… Apply performance optimizations\n    train_ds = train_ds.shuffle(1000, seed=CONFIG['SEED']).prefetch(tf.data.experimental.AUTOTUNE)\n    val_ds = val_ds.prefetch(tf.data.experimental.AUTOTUNE)\n\n    print(f\"âœ” Training Batches: {tf.data.experimental.cardinality(train_ds).numpy()}, Validation Batches: {val_size}\")\n    \n    return train_ds, val_ds\n\n# âœ… Create ConvNeXt Model\ndef create_convnext_model():\n    \"\"\"Create and compile ConvNeXt model.\"\"\"\n    base_model = tf.keras.applications.ConvNeXtBase(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=(*CONFIG['IMAGE_SIZE'], 3),\n        pooling='avg'\n    )\n\n    # âœ… Fine-Tuning: Freeze all but the last 30 layers\n    base_model.trainable = True\n    for layer in base_model.layers[:-30]:\n        layer.trainable = False\n\n    model = keras.Sequential([\n        base_model,\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(512, activation=\"swish\"),\n        keras.layers.Dropout(0.4),\n        keras.layers.Dense(CONFIG['NUM_CLASSES'], activation=\"softmax\")\n    ])\n\n    model.compile(\n        optimizer=keras.optimizers.AdamW(learning_rate=CONFIG['LEARNING_RATE'], weight_decay=0.0001),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    return model\n\n# âœ… Train and Evaluate using 6-Fold Cross-Validation\ndef train_and_evaluate():\n    train_ds, val_ds = load_dataset()\n\n    for fold in range(CONFIG['K_FOLDS']):\n        print(f\"\\nğŸš€ Training Fold {fold + 1}/{CONFIG['K_FOLDS']}\")\n\n        model = create_convnext_model()\n\n        checkpoint_path = os.path.join(CHECKPOINT_DIR, f'model_fold_{fold+1}.keras')\n        callbacks = [\n            ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True),\n            EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),\n            ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=2)\n        ]\n\n        history = model.fit(\n            train_ds,\n            validation_data=val_ds,\n            epochs=CONFIG['EPOCHS'],\n            callbacks=callbacks,\n            verbose=1\n        )\n\n        plot_results(history, fold)\n        keras.backend.clear_session()\n\n# âœ… Plot Training Results\ndef plot_results(history, fold):\n    plt.figure(figsize=(12, 5))\n    \n    # Accuracy Plot\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n    plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n    plt.title(f\"Accuracy - Fold {fold+1}\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n\n    # Loss Plot\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n    plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n    plt.title(f\"Loss - Fold {fold+1}\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    plt.savefig(os.path.join(RESULTS_DIR, f'metrics_fold_{fold+1}.png'))\n    plt.close()\n\n# âœ… Start Training\nif __name__ == \"__main__\":\n    print(\"ğŸŒ¿ Starting Colocasia Plant Disease Classification Training\")\n    train_and_evaluate()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:58:43.729430Z","iopub.execute_input":"2025-02-24T03:58:43.729859Z"}},"outputs":[{"name":"stdout","text":"ğŸŒ¿ Starting Colocasia Plant Disease Classification Training\n\nğŸ“‚ Loading dataset with proper validation split...\nFound 40347 files belonging to 6 classes.\nâœ” Training Batches: 2018, Validation Batches: 504\n\nğŸš€ Training Fold 1/6\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_base_notop.h5\n\u001b[1m350926856/350926856\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 156ms/step - accuracy: 0.9803 - loss: 0.0598 - val_accuracy: 1.0000 - val_loss: 7.5182e-06 - learning_rate: 1.0000e-04\nEpoch 2/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 148ms/step - accuracy: 0.9983 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 1.3559e-05 - learning_rate: 1.0000e-04\nEpoch 3/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 148ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9999 - val_loss: 5.9260e-04 - learning_rate: 1.0000e-04\nEpoch 4/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 148ms/step - accuracy: 0.9999 - loss: 4.8710e-04 - val_accuracy: 1.0000 - val_loss: 1.0396e-07 - learning_rate: 2.0000e-05\n\nğŸš€ Training Fold 2/6\nEpoch 1/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 155ms/step - accuracy: 0.9812 - loss: 0.0578 - val_accuracy: 1.0000 - val_loss: 9.2744e-05 - learning_rate: 1.0000e-04\nEpoch 2/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 147ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9999 - val_loss: 2.3463e-04 - learning_rate: 1.0000e-04\nEpoch 3/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 4.7339e-04 - val_accuracy: 0.9994 - val_loss: 7.3124e-04 - learning_rate: 1.0000e-04\nEpoch 4/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 147ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.7181e-07 - learning_rate: 2.0000e-05\n\nğŸš€ Training Fold 3/6\nEpoch 1/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 156ms/step - accuracy: 0.9819 - loss: 0.0521 - val_accuracy: 1.0000 - val_loss: 8.8020e-06 - learning_rate: 1.0000e-04\nEpoch 2/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 148ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 4.2889e-07 - learning_rate: 1.0000e-04\nEpoch 3/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 148ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.2736e-08 - learning_rate: 1.0000e-04\nEpoch 4/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 148ms/step - accuracy: 0.9999 - loss: 2.4976e-04 - val_accuracy: 1.0000 - val_loss: 1.2432e-08 - learning_rate: 2.0000e-05\n\nğŸš€ Training Fold 4/6\nEpoch 1/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 156ms/step - accuracy: 0.9816 - loss: 0.0549 - val_accuracy: 1.0000 - val_loss: 1.7764e-06 - learning_rate: 1.0000e-04\nEpoch 2/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 148ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9996 - val_loss: 0.0016 - learning_rate: 1.0000e-04\nEpoch 3/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 148ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 5.6232e-06 - learning_rate: 1.0000e-04\nEpoch 4/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 147ms/step - accuracy: 0.9997 - loss: 4.7035e-04 - val_accuracy: 1.0000 - val_loss: 2.7062e-07 - learning_rate: 2.0000e-05\n\nğŸš€ Training Fold 5/6\nEpoch 1/20\n\u001b[1m2018/2018\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 156ms/step - accuracy: 0.9791 - loss: 0.0578 - val_accuracy: 1.0000 - val_loss: 8.7511e-06 - learning_rate: 1.0000e-04\nEpoch 2/20\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport os\nimport glob\n\n# âœ… Check existing checkpoints\ndef get_last_trained_fold():\n    \"\"\"Finds the last successfully trained fold from saved checkpoints.\"\"\"\n    checkpoint_files = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, \"model_fold_*.keras\")))\n    \n    if checkpoint_files:\n        last_fold = max([int(f.split(\"_\")[-1].split(\".\")[0]) for f in checkpoint_files])  # Extract fold number\n        print(f\"ğŸ“Œ Resuming from Fold {last_fold + 1}\")\n        return last_fold\n    else:\n        print(\"ğŸ”„ No previous training found. Starting from scratch.\")\n        return 0  # Start from first fold\n\n# âœ… Resume Training\ndef resume_training():\n    train_ds, val_ds = load_dataset()\n    last_trained_fold = get_last_trained_fold()\n\n    for fold in range(last_trained_fold, CONFIG['K_FOLDS']):\n        print(f\"\\nğŸš€ Resuming Training: Fold {fold + 1}/{CONFIG['K_FOLDS']}\")\n\n        model = create_convnext_model()\n\n        checkpoint_path = os.path.join(CHECKPOINT_DIR, f'model_fold_{fold+1}.keras')\n\n        # âœ… Load previous weights if available\n        if os.path.exists(checkpoint_path):\n            print(f\"ğŸ”„ Loading existing weights from {checkpoint_path}\")\n            model.load_weights(checkpoint_path)\n\n        callbacks = [\n            ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True),\n            EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),\n            ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=2)\n        ]\n\n        history = model.fit(\n            train_ds,\n            validation_data=val_ds,\n            epochs=CONFIG['EPOCHS'],\n            callbacks=callbacks,\n            verbose=1\n        )\n\n        plot_results(history, fold)\n        keras.backend.clear_session()\n\n# âœ… Start or Resume Training\nif __name__ == \"__main__\":\n    print(\"ğŸŒ¿ Resuming Colocasia Plant Disease Classification Training\")\n    resume_training()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport os\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\n\n# âœ… Enhanced Training Results Visualization\ndef plot_results(history, fold):\n    \"\"\"Plot enhanced training results for each fold.\"\"\"\n    sns.set_style(\"whitegrid\")\n\n    plt.figure(figsize=(14, 5))\n\n    # Accuracy Plot\n    plt.subplot(1, 2, 1)\n    sns.lineplot(data={\"Train Accuracy\": history.history[\"accuracy\"], \"Val Accuracy\": history.history[\"val_accuracy\"]})\n    plt.title(f\"Accuracy - Fold {fold+1}\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend([\"Train Accuracy\", \"Validation Accuracy\"])\n    plt.grid()\n\n    # Loss Plot\n    plt.subplot(1, 2, 2)\n    sns.lineplot(data={\"Train Loss\": history.history[\"loss\"], \"Val Loss\": history.history[\"val_loss\"]})\n    plt.title(f\"Loss - Fold {fold+1}\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend([\"Train Loss\", \"Validation Loss\"])\n    plt.grid()\n\n    plt.savefig(os.path.join(\"results\", f'metrics_fold_{fold+1}.png'))\n    plt.close()\n\n# âœ… K-Fold Validation Accuracy Bar Plot\ndef plot_kfold_results(fold_accuracies):\n    \"\"\"Plot K-Fold validation accuracy across all folds.\"\"\"\n    plt.figure(figsize=(8, 6))\n    sns.barplot(x=[f\"Fold {i+1}\" for i in range(len(fold_accuracies))], y=fold_accuracies, palette=\"Blues_d\")\n    plt.title(\"K-Fold Cross-Validation Accuracy\", fontsize=14, fontweight='bold')\n    plt.xlabel(\"Fold\")\n    plt.ylabel(\"Validation Accuracy\")\n    plt.ylim(0, 1)\n    plt.grid(axis='y')\n    plt.savefig(os.path.join(\"results\", \"kfold_accuracy.png\"))\n    plt.close()\n\n# âœ… Classification Report & Confusion Matrix\ndef plot_classification_report(y_true, y_pred, class_names):\n    \"\"\"Generate classification report and confusion matrix.\"\"\"\n    report = classification_report(y_true, y_pred, target_names=class_names)\n    print(\"\\nğŸ“ Classification Report:\\n\", report)\n\n    cm = confusion_matrix(y_true, y_pred)\n    \n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.savefig(os.path.join(\"results\", \"confusion_matrix.png\"))\n    plt.close()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Training Results\ndef plot_results(history, fold):\n    plt.figure(figsize=(10, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n    plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n    plt.title(f\"Accuracy - Fold {fold+1}\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n    plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n    plt.title(f\"Loss - Fold {fold+1}\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    \n    plt.savefig(os.path.join(RESULTS_DIR, f'metrics_fold_{fold+1}.png'))\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T03:53:16.164557Z","iopub.execute_input":"2025-02-24T03:53:16.164867Z","iopub.status.idle":"2025-02-24T03:53:16.170341Z","shell.execute_reply.started":"2025-02-24T03:53:16.164842Z","shell.execute_reply":"2025-02-24T03:53:16.169373Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}